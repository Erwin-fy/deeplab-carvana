name: "${NET_ID}"

layer {
  name: "data"
  type: "ImageSegData"
  top: "data"
  top: "label"
  top: "data_dim"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    #crop_size: 513
    #crop_size: 321
    crop_height: 1089
    crop_width: 1633
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
  image_data_param {
    root_folder: "${DATA_ROOT}"
    source: "${EXP}/list/${TEST_SET}.txt"
    batch_size: 1
    shuffle: true
    # label_type: PIXEL
    label_type: NONE
  }
}

### shrink data ###
layer {
  bottom: "data"
  top: "data_res05"
  name: "data_res05"
  type: "Interp"
  interp_param {
    shrink_factor: 2
    pad_beg: 0
    pad_end: 0
      
  }
}
layer {
  bottom: "data"
  top: "data_res075"
  name: "data_res075"
  type: "Interp"
  interp_param {
    shrink_factor: 4
    zoom_factor: 3
    pad_beg: 0
    pad_end: 0
      
  }
}


###################### DeepLab ####################

### resolution 1 ###
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 3
    pad: 1
    stride: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}

layer {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}

### hole = 6
layer {
  name: "fc6_1"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6_1"
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    dilation: 6
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "fc6_1"
  top: "fc6_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "fc6_1"
  top: "fc6_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_1"
  type: "Convolution"
  bottom: "fc6_1"
  top: "fc7_1"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
 name: "relu7_1"
  type: "ReLU"
  bottom: "fc7_1"
  top: "fc7_1"
}
layer {
  name: "drop7_1"
  type: "Dropout"
  bottom: "fc7_1"
  top: "fc7_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_1"
  type: "Convolution"
  bottom: "fc7_1"
  top: "fc8_${EXP}_1"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_1"
#   type: "Convolution"
#   bottom: "pool5"
#   top: "fc8_${EXP}_1"
#   param {
#     name: "fc8_${EXP}_1_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_1_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     pad: 6
#     dilation: 6
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 12
layer {
  name: "fc6_2"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6_2"
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    dilation: 12
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "fc6_2"
  top: "fc6_2"
}
layer {
  name: "drop6_2"
  type: "Dropout"
  bottom: "fc6_2"
  top: "fc6_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_2"
  type: "Convolution"
  bottom: "fc6_2"
  top: "fc7_2"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "fc7_2"
  top: "fc7_2"
}
layer {
  name: "drop7_2"
  type: "Dropout"
  bottom: "fc7_2"
  top: "fc7_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_2"
  type: "Convolution"
  bottom: "fc7_2"
  top: "fc8_${EXP}_2"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_2"
#   type: "Convolution"
#   bottom: "pool5"
#   top: "fc8_${EXP}_2"
#   param {
#     name: "fc8_${EXP}_2_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_2_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 12
#     pad: 12
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 18
layer {
  name: "fc6_3"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6_3"
  convolution_param {
    num_output: 1024
    pad: 18
    kernel_size: 3
    dilation: 18
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "fc6_3"
  top: "fc6_3"
}
layer {
  name: "drop6_3"
  type: "Dropout"
  bottom: "fc6_3"
  top: "fc6_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_3"
  type: "Convolution"
  bottom: "fc6_3"
  top: "fc7_3"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "fc7_3"
  top: "fc7_3"
}
layer {
  name: "drop7_3"
  type: "Dropout"
  bottom: "fc7_3"
  top: "fc7_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_3"
  type: "Convolution"
  bottom: "fc7_3"
  top: "fc8_${EXP}_3"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

# layer {
#   name: "fc8_${EXP}_3"
#   type: "Convolution"
#   bottom: "pool5"
#   top: "fc8_${EXP}_3"
#   param {
#     name: "fc8_${EXP}_3_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_3_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 18
#     pad: 18
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 24
layer {
  name: "fc6_4"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6_4"
  convolution_param {
    num_output: 1024
    pad: 24
    kernel_size: 3
    dilation: 24
  }
}
layer {
  name: "relu6_4"
  type: "ReLU"
  bottom: "fc6_4"
  top: "fc6_4"
}
layer {
  name: "drop6_4"
  type: "Dropout"
  bottom: "fc6_4"
  top: "fc6_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_4"
  type: "Convolution"
  bottom: "fc6_4"
  top: "fc7_4"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_4"
  type: "ReLU"
  bottom: "fc7_4"
  top: "fc7_4"
}
layer {
  name: "drop7_4"
  type: "Dropout"
  bottom: "fc7_4"
  top: "fc7_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_4"
  type: "Convolution"
  bottom: "fc7_4"
  top: "fc8_${EXP}_4"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_4"
#   type: "Convolution"
#   bottom: "pool5"
#   top: "fc8_${EXP}_4"
#   param {
#     name: "fc8_${EXP}_4_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_4_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 24
#     pad: 24
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### SUM the four branches
layer {
  bottom: "fc8_${EXP}_1"
  bottom: "fc8_${EXP}_2"
  bottom: "fc8_${EXP}_3"
  bottom: "fc8_${EXP}_4"
  top: "fc8_${EXP}"
  name: "fc8_${EXP}"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

### resolution 0.75 ###
layer {
  name: "conv1_1_res075"
  type: "Convolution"
  bottom: "data_res075"
  top: "conv1_1_res075"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1_res075"
  type: "ReLU"
  bottom: "conv1_1_res075"
  top: "conv1_1_res075"
}
layer {
  name: "conv1_2_res075"
  type: "Convolution"
  bottom: "conv1_1_res075"
  top: "conv1_2_res075"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2_res075"
  type: "ReLU"
  bottom: "conv1_2_res075"
  top: "conv1_2_res075"
}
layer {
  name: "pool1_res075"
  type: "Pooling"
  bottom: "conv1_2_res075"
  top: "pool1_res075"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1_res075"
  type: "Convolution"
  bottom: "pool1_res075"
  top: "conv2_1_res075"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1_res075"
  type: "ReLU"
  bottom: "conv2_1_res075"
  top: "conv2_1_res075"
}
layer {
  name: "conv2_2_res075"
  type: "Convolution"
  bottom: "conv2_1_res075"
  top: "conv2_2_res075"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2_res075"
  type: "ReLU"
  bottom: "conv2_2_res075"
  top: "conv2_2_res075"
}
layer {
  name: "pool2_res075"
  type: "Pooling"
  bottom: "conv2_2_res075"
  top: "pool2_res075"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv3_1_res075"
  type: "Convolution"
  bottom: "pool2_res075"
  top: "conv3_1_res075"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1_res075"
  type: "ReLU"
  bottom: "conv3_1_res075"
  top: "conv3_1_res075"
}
layer {
  name: "conv3_2_res075"
  type: "Convolution"
  bottom: "conv3_1_res075"
  top: "conv3_2_res075"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2_res075"
  type: "ReLU"
  bottom: "conv3_2_res075"
  top: "conv3_2_res075"
}
layer {
  name: "conv3_3_res075"
  type: "Convolution"
  bottom: "conv3_2_res075"
  top: "conv3_3_res075"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3_res075"
  type: "ReLU"
  bottom: "conv3_3_res075"
  top: "conv3_3_res075"
}
layer {
  name: "pool3_res075"
  type: "Pooling"
  bottom: "conv3_3_res075"
  top: "pool3_res075"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv4_1_res075"
  type: "Convolution"
  bottom: "pool3_res075"
  top: "conv4_1_res075"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1_res075"
  type: "ReLU"
  bottom: "conv4_1_res075"
  top: "conv4_1_res075"
}
layer {
  name: "conv4_2_res075"
  type: "Convolution"
  bottom: "conv4_1_res075"
  top: "conv4_2_res075"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2_res075"
  type: "ReLU"
  bottom: "conv4_2_res075"
  top: "conv4_2_res075"
}
layer {
  name: "conv4_3_res075"
  type: "Convolution"
  bottom: "conv4_2_res075"
  top: "conv4_3_res075"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3_res075"
  type: "ReLU"
  bottom: "conv4_3_res075"
  top: "conv4_3_res075"
}
layer {
  bottom: "conv4_3_res075"
  top: "pool4_res075"
  name: "pool4_res075"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 3
    pad: 1
    stride: 1
  }
}
layer {
  name: "conv5_1_res075"
  type: "Convolution"
  bottom: "pool4_res075"
  top: "conv5_1_res075"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1_res075"
  type: "ReLU"
  bottom: "conv5_1_res075"
  top: "conv5_1_res075"
}
layer {
  name: "conv5_2_res075"
  type: "Convolution"
  bottom: "conv5_1_res075"
  top: "conv5_2_res075"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2_res075"
  type: "ReLU"
  bottom: "conv5_2_res075"
  top: "conv5_2_res075"
}
layer {
  name: "conv5_3_res075"
  type: "Convolution"
  bottom: "conv5_2_res075"
  top: "conv5_3_res075"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3_res075"
  type: "ReLU"
  bottom: "conv5_3_res075"
  top: "conv5_3_res075"
}

layer {
  bottom: "conv5_3_res075"
  top: "pool5_res075"
  name: "pool5_res075"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}

### classifiers
### hole = 6
layer {
  name: "fc6_1_res075"
  type: "Convolution"
  bottom: "pool5_res075"
  top: "fc6_1_res075"
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    dilation: 6
  }
}
layer {
  name: "relu6_1_res075"
  type: "ReLU"
  bottom: "fc6_1_res075"
  top: "fc6_1_res075"
}
layer {
  name: "drop6_1_res075"
  type: "Dropout"
  bottom: "fc6_1_res075"
  top: "fc6_1_res075"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_1_res075"
  type: "Convolution"
  bottom: "fc6_1_res075"
  top: "fc7_1_res075"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_1_res075"
  type: "ReLU"
  bottom: "fc7_1_res075"
  top: "fc7_1_res075"
}
layer {
  name: "drop7_1_res075"
  type: "Dropout"
  bottom: "fc7_1_res075"
  top: "fc7_1_res075"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_1_res075"
  type: "Convolution"
  bottom: "fc7_1_res075"
  top: "fc8_${EXP}_1_res075"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_1_res075"
#   type: "Convolution"
#   bottom: "pool5_res075"
#   top: "fc8_${EXP}_1_res075"
#   param {
#     name: "fc8_${EXP}_1_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_1_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     pad: 6
#     dilation: 6
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 12
layer {
  name: "fc6_2_res075"
  type: "Convolution"
  bottom: "pool5_res075"
  top: "fc6_2_res075"
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    dilation: 12
  }
}
layer {
  name: "relu6_2_res075"
  type: "ReLU"
  bottom: "fc6_2_res075"
  top: "fc6_2_res075"
}
layer {
  name: "drop6_2_res075"
  type: "Dropout"
  bottom: "fc6_2_res075"
  top: "fc6_2_res075"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_2_res075"
  type: "Convolution"
  bottom: "fc6_2_res075"
  top: "fc7_2_res075"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_2_res075"
  type: "ReLU"
  bottom: "fc7_2_res075"
  top: "fc7_2_res075"
}
layer {
  name: "drop7_2_res075"
  type: "Dropout"
  bottom: "fc7_2_res075"
  top: "fc7_2_res075"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_2_res075"
  type: "Convolution"
  bottom: "fc7_2_res075"
  top: "fc8_${EXP}_2_res075"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_2_res075"
#   type: "Convolution"
#   bottom: "pool5_res075"
#   top: "fc8_${EXP}_2_res075"
#   param {
#     name: "fc8_${EXP}_2_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_2_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 12
#     pad: 12
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 18
layer {
  name: "fc6_3_res075"
  type: "Convolution"
  bottom: "pool5_res075"
  top: "fc6_3_res075"
  convolution_param {
    num_output: 1024
    pad: 18
    kernel_size: 3
    dilation: 18
  }
}
layer {
  name: "relu6_3_res075"
  type: "ReLU"
  bottom: "fc6_3_res075"
  top: "fc6_3_res075"
}
layer {
  name: "drop6_3_res075"
  type: "Dropout"
  bottom: "fc6_3_res075"
  top: "fc6_3_res075"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_3_res075"
  type: "Convolution"
  bottom: "fc6_3_res075"
  top: "fc7_3_res075"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_3_res075"
  type: "ReLU"
  bottom: "fc7_3_res075"
  top: "fc7_3_res075"
}
layer {
  name: "drop7_3_res075"
  type: "Dropout"
  bottom: "fc7_3_res075"
  top: "fc7_3_res075"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_3_res075"
  type: "Convolution"
  bottom: "fc7_3_res075"
  top: "fc8_${EXP}_3_res075"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_3_res075"
#   type: "Convolution"
#   bottom: "pool5_res075"
#   top: "fc8_${EXP}_3_res075"
#   param {
#     name: "fc8_${EXP}_3_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_3_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 18
#     pad: 18
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 24
layer {
  name: "fc6_4_res075"
  type: "Convolution"
  bottom: "pool5_res075"
  top: "fc6_4_res075"
  convolution_param {
    num_output: 1024
    pad: 24
    kernel_size: 3
    dilation: 24
  }
}
layer {
  name: "relu6_4_res075"
  type: "ReLU"
  bottom: "fc6_4_res075"
  top: "fc6_4_res075"
}
layer {
  name: "drop6_4_res075"
  type: "Dropout"
  bottom: "fc6_4_res075"
  top: "fc6_4_res075"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_4_res075"
  type: "Convolution"
  bottom: "fc6_4_res075"
  top: "fc7_4_res075"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_4_res075"
  type: "ReLU"
  bottom: "fc7_4_res075"
  top: "fc7_4_res075"
}
layer {
  name: "drop7_4_res075"
  type: "Dropout"
  bottom: "fc7_4_res075"
  top: "fc7_4_res075"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_4_res075"
  type: "Convolution"
  bottom: "fc7_4_res075"
  top: "fc8_${EXP}_4_res075"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_4_res075"
#   type: "Convolution"
#   bottom: "pool5_res075"
#   top: "fc8_${EXP}_4_res075"
#   param {
#     name: "fc8_${EXP}_4_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_4_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 24
#     pad: 24
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### SUM the four branches
layer {
  bottom: "fc8_${EXP}_1_res075"
  bottom: "fc8_${EXP}_2_res075"
  bottom: "fc8_${EXP}_3_res075"
  bottom: "fc8_${EXP}_4_res075"
  top: "fc8_${EXP}_res075"
  name: "fc8_${EXP}_res075"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}


### resolution 0.5 ###
layer {
  name: "conv1_1_res05"
  type: "Convolution"
  bottom: "data_res05"
  top: "conv1_1_res05"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1_res05"
  type: "ReLU"
  bottom: "conv1_1_res05"
  top: "conv1_1_res05"
}
layer {
  name: "conv1_2_res05"
  type: "Convolution"
  bottom: "conv1_1_res05"
  top: "conv1_2_res05"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2_res05"
  type: "ReLU"
  bottom: "conv1_2_res05"
  top: "conv1_2_res05"
}
layer {
  name: "pool1_res05"
  type: "Pooling"
  bottom: "conv1_2_res05"
  top: "pool1_res05"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1_res05"
  type: "Convolution"
  bottom: "pool1_res05"
  top: "conv2_1_res05"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1_res05"
  type: "ReLU"
  bottom: "conv2_1_res05"
  top: "conv2_1_res05"
}
layer {
  name: "conv2_2_res05"
  type: "Convolution"
  bottom: "conv2_1_res05"
  top: "conv2_2_res05"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2_res05"
  type: "ReLU"
  bottom: "conv2_2_res05"
  top: "conv2_2_res05"
}
layer {
  name: "pool2_res05"
  type: "Pooling"
  bottom: "conv2_2_res05"
  top: "pool2_res05"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv3_1_res05"
  type: "Convolution"
  bottom: "pool2_res05"
  top: "conv3_1_res05"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1_res05"
  type: "ReLU"
  bottom: "conv3_1_res05"
  top: "conv3_1_res05"
}
layer {
  name: "conv3_2_res05"
  type: "Convolution"
  bottom: "conv3_1_res05"
  top: "conv3_2_res05"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2_res05"
  type: "ReLU"
  bottom: "conv3_2_res05"
  top: "conv3_2_res05"
}
layer {
  name: "conv3_3_res05"
  type: "Convolution"
  bottom: "conv3_2_res05"
  top: "conv3_3_res05"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3_res05"
  type: "ReLU"
  bottom: "conv3_3_res05"
  top: "conv3_3_res05"
}
layer {
  name: "pool3_res05"
  type: "Pooling"
  bottom: "conv3_3_res05"
  top: "pool3_res05"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv4_1_res05"
  type: "Convolution"
  bottom: "pool3_res05"
  top: "conv4_1_res05"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1_res05"
  type: "ReLU"
  bottom: "conv4_1_res05"
  top: "conv4_1_res05"
}
layer {
  name: "conv4_2_res05"
  type: "Convolution"
  bottom: "conv4_1_res05"
  top: "conv4_2_res05"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2_res05"
  type: "ReLU"
  bottom: "conv4_2_res05"
  top: "conv4_2_res05"
}
layer {
  name: "conv4_3_res05"
  type: "Convolution"
  bottom: "conv4_2_res05"
  top: "conv4_3_res05"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3_res05"
  type: "ReLU"
  bottom: "conv4_3_res05"
  top: "conv4_3_res05"
}
layer {
  bottom: "conv4_3_res05"
  top: "pool4_res05"
  name: "pool4_res05"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 3
    pad: 1
    stride: 1
  }
}
layer {
  name: "conv5_1_res05"
  type: "Convolution"
  bottom: "pool4_res05"
  top: "conv5_1_res05"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1_res05"
  type: "ReLU"
  bottom: "conv5_1_res05"
  top: "conv5_1_res05"
}
layer {
  name: "conv5_2_res05"
  type: "Convolution"
  bottom: "conv5_1_res05"
  top: "conv5_2_res05"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2_res05"
  type: "ReLU"
  bottom: "conv5_2_res05"
  top: "conv5_2_res05"
}
layer {
  name: "conv5_3_res05"
  type: "Convolution"
  bottom: "conv5_2_res05"
  top: "conv5_3_res05"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3_res05"
  type: "ReLU"
  bottom: "conv5_3_res05"
  top: "conv5_3_res05"
}

layer {
  bottom: "conv5_3_res05"
  top: "pool5_res05"
  name: "pool5_res05"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}

### classifiers
### hole = 6
layer {
  name: "fc6_1_res05"
  type: "Convolution"
  bottom: "pool5_res05"
  top: "fc6_1_res05"
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    dilation: 6
  }
}
layer {
  name: "relu6_1_res05"
  type: "ReLU"
  bottom: "fc6_1_res05"
  top: "fc6_1_res05"
}
layer {
  name: "drop6_1_res05"
  type: "Dropout"
  bottom: "fc6_1_res05"
  top: "fc6_1_res05"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_1_res05"
  type: "Convolution"
  bottom: "fc6_1_res05"
  top: "fc7_1_res05"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_1_res05"
  type: "ReLU"
  bottom: "fc7_1_res05"
  top: "fc7_1_res05"
}
layer {
  name: "drop7_1_res05"
  type: "Dropout"
  bottom: "fc7_1_res05"
  top: "fc7_1_res05"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_1_res05"
  type: "Convolution"
  bottom: "fc7_1_res05"
  top: "fc8_${EXP}_1_res05"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_1_res05"
#   type: "Convolution"
#   bottom: "pool5_res05"
#   top: "fc8_${EXP}_1_res05"
#   param {
#     name: "fc8_${EXP}_1_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_1_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: 2
#     kernel_size: 3
#     pad: 6
#     dilation: 6
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 12
layer {
  name: "fc6_2_res05"
  type: "Convolution"
  bottom: "pool5_res05"
  top: "fc6_2_res05"
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    dilation: 12
  }
}
layer {
  name: "relu6_2_res05"
  type: "ReLU"
  bottom: "fc6_2_res05"
  top: "fc6_2_res05"
}
layer {
  name: "drop6_2_res05"
  type: "Dropout"
  bottom: "fc6_2_res05"
  top: "fc6_2_res05"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_2_res05"
  type: "Convolution"
  bottom: "fc6_2_res05"
  top: "fc7_2_res05"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_2_res05"
  type: "ReLU"
  bottom: "fc7_2_res05"
  top: "fc7_2_res05"
}
layer {
  name: "drop7_2_res05"
  type: "Dropout"
  bottom: "fc7_2_res05"
  top: "fc7_2_res05"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_2_res05"
  type: "Convolution"
  bottom: "fc7_2_res05"
  top: "fc8_${EXP}_2_res05"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_2_res05"
#   type: "Convolution"
#   bottom: "pool5_res05"
#   top: "fc8_${EXP}_2_res05"
#   param {
#     name: "fc8_${EXP}_2_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_2_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 12
#     pad: 12
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 18
layer {
  name: "fc6_3_res05"
  type: "Convolution"
  bottom: "pool5_res05"
  top: "fc6_3_res05"
  convolution_param {
    num_output: 1024
    pad: 18
    kernel_size: 3
    dilation: 18
  }
}
layer {
  name: "relu6_3_res05"
  type: "ReLU"
  bottom: "fc6_3_res05"
  top: "fc6_3_res05"
}
layer {
  name: "drop6_3_res05"
  type: "Dropout"
  bottom: "fc6_3_res05"
  top: "fc6_3_res05"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_3_res05"
  type: "Convolution"
  bottom: "fc6_3_res05"
  top: "fc7_3_res05"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_3_res05"
  type: "ReLU"
  bottom: "fc7_3_res05"
  top: "fc7_3_res05"
}
layer {
  name: "drop7_3_res05"
  type: "Dropout"
  bottom: "fc7_3_res05"
  top: "fc7_3_res05"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_3_res05"
  type: "Convolution"
  bottom: "fc7_3_res05"
  top: "fc8_${EXP}_3_res05"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_3_res05"
#   type: "Convolution"
#   bottom: "pool5_res05"
#   top: "fc8_${EXP}_3_res05"
#   param {
#     name: "fc8_${EXP}_3_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_3_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 18
#     pad: 18
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### hole = 24
layer {
  name: "fc6_4_res05"
  type: "Convolution"
  bottom: "pool5_res05"
  top: "fc6_4_res05"
  convolution_param {
    num_output: 1024
    pad: 24
    kernel_size: 3
    dilation: 24
  }
}
layer {
  name: "relu6_4_res05"
  type: "ReLU"
  bottom: "fc6_4_res05"
  top: "fc6_4_res05"
}
layer {
  name: "drop6_4_res05"
  type: "Dropout"
  bottom: "fc6_4_res05"
  top: "fc6_4_res05"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_4_res05"
  type: "Convolution"
  bottom: "fc6_4_res05"
  top: "fc7_4_res05"
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_4_res05"
  type: "ReLU"
  bottom: "fc7_4_res05"
  top: "fc7_4_res05"
}
layer {
  name: "drop7_4_res05"
  type: "Dropout"
  bottom: "fc7_4_res05"
  top: "fc7_4_res05"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_${EXP}_4_res05"
  type: "Convolution"
  bottom: "fc7_4_res05"
  top: "fc8_${EXP}_4_res05"
  convolution_param {
    num_output: ${NUM_LABELS}
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# layer {
#   name: "fc8_${EXP}_4_res05"
#   type: "Convolution"
#   bottom: "pool5_res05"
#   top: "fc8_${EXP}_4_res05"
#   param {
#     name: "fc8_${EXP}_4_w"
#     lr_mult: 10
#     decay_mult: 1
#   }
#   param {
#     name: "fc8_${EXP}_4_b"
#     lr_mult: 20
#     decay_mult: 0
#   }
#   convolution_param {
#     num_output: ${NUM_LABELS}
#     kernel_size: 3
#     dilation: 24
#     pad: 24
#     weight_filler {
#       type: "gaussian"
#       std: 0.01
#     }
#     bias_filler {
#       type: "constant"
#       value: 0
#     }
#   }
# }

### SUM the four branches
layer {
  bottom: "fc8_${EXP}_1_res05"
  bottom: "fc8_${EXP}_2_res05"
  bottom: "fc8_${EXP}_3_res05"
  bottom: "fc8_${EXP}_4_res05"
  top: "fc8_${EXP}_res05"
  name: "fc8_${EXP}_res05"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

############### upsampling ##################
layer {
  bottom: "fc8_${EXP}_res05"
  top: "fc8_${EXP}_res05_interp"
  name: "fc8_${EXP}_res05_interp"
  type: "Interp"
  interp_param {
    zoom_factor: 2
    pad_beg: 0
    pad_end: 0
  }
}

layer {
  bottom: "fc8_${EXP}_res075"
  top: "fc8_${EXP}_res075_interp"
  name: "fc8_${EXP}_res075_interp"
  type: "Interp"
  interp_param {
    zoom_factor: 4
    shrink_factor: 3    
    pad_beg: 0
    pad_end: 0
  }
}

############### merging multiscale results #####################
layer {
  bottom: "fc8_${EXP}"
  bottom: "fc8_${EXP}_res075_interp"
  bottom: "fc8_${EXP}_res05_interp"
  top: "fc_fusion"
  name: "fc_fusion"
  type: "Eltwise"
  eltwise_param {
    operation: MAX
  }
}

##################### original resolution #######################
layer {
  bottom: "fc_fusion"
  top: "fc8_interp"
  name: "fc8_interp"
  type: "Interp"
  interp_param {
    zoom_factor: 8
  }
}
layer {
  bottom: "fc8_interp"
  top: "fc8_interp_argmax"
  name: "fc8_interp_argmax"
  type: "ArgMax"
  argmax_param {
    axis: 1
  }
}
layer {
  name: "fc8_png"
  type: "PNGWrite"
  bottom: "fc8_interp_argmax"
#  bottom: "fc8_interp"
  include {
    phase: TEST
  }
  png_write_param {
    prefix: "${FEATURE_DIR}/${TEST_SET}/fc8/"
    source: "${EXP}/list/${TEST_SET}_id.txt"
    strip: 0
    period: 1
  }
}

layer {
  name: "accuracy"
  type: "SegAccuracy"
  bottom: "fc8_interp"
  bottom: "label"
  top: "fc8_accuracy"
  seg_accuracy_param {
    ignore_label: 255
    reset: false
  }
}


layer {
  name: "silence"
  type: "Silence"
  bottom: "data_dim"
}

